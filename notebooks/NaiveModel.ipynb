{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2289,"status":"ok","timestamp":1713253355968,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"MHjC_3NdRm39","outputId":"d61305ae-66e4-40c2-aeb0-45108a9eb55d"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1713253355969,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"ZDJ_iLd7Rw8b"},"outputs":[],"source":["# import pandas as pd\n","# from distributed import Client, LocalCluster\n","# cluster = LocalCluster(memory_limit='8GB')\n","# client = Client(cluster)\n","import modin.pandas as pd\n","import modin.config as modin_cfg\n","modin_cfg.Engine.put(\"ray\")  # Modin will use Ray\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"elapsed":6,"status":"error","timestamp":1713253355969,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"rNnIzKLIRxxV","outputId":"3e004d85-922e-4533-8ef5-db431fe3ad7f"},"outputs":[],"source":["# kaggle_data = pd.read_csv('/content/drive/MyDrive/NUS_MSBA/BT5153_Final Group Project_Shared Folder/Data/kaggle_data.csv')\n","# wiki_data = pd.read_csv('/content/drive/MyDrive/NUS_MSBA/BT5153_Final Group Project_Shared Folder/Data/wiki_data.csv')\n","# essay = pd.read_csv('/content/drive/MyDrive/NUS_MSBA/BT5153_Final Group Project_Shared Folder/Data/competition_essay.csv')\n","# test_data = essay.drop(columns='Remark')\n","\n","train_data_processed = pd.read_csv(\"kaggle_preprocessed.csv\")\n","test_data_processed = pd.read_csv(\"new_essay_val_preprocessed.csv\")\n","test_data_dep_processed = pd.read_csv(\"test_data_preprocessed.csv\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1713253355969,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"JnsiyS8Pz7J2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>carfree cities become subject increasing inter...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>car free cities carfree cities concept gaining...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sustainable urban future carfree cities emergi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>pioneering sustainable urban living era marked...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>path sustainable urban living age rapid urbani...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  carfree cities become subject increasing inter...      1\n","1  car free cities carfree cities concept gaining...      1\n","2  sustainable urban future carfree cities emergi...      1\n","3  pioneering sustainable urban living era marked...      1\n","4  path sustainable urban living age rapid urbani...      1"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# for each data, keep only text and label columns\n","train_data_processed = train_data_processed[['text', 'label']]\n","test_data_processed = test_data_processed[['text', 'label']]\n","test_data_dep_processed = test_data_dep_processed[['text', 'label']]\n","\n","train_data_processed.head()"]},{"cell_type":"markdown","metadata":{"id":"lYsKp7HC2xJ0"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1713253355969,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"oc1iRFMKx_KW"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (24.0)\n","Requirement already satisfied: transformers in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (4.40.1)\n","Requirement already satisfied: filelock in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (0.23.0)\n","Requirement already satisfied: numpy>=1.17 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (2024.4.28)\n","Requirement already satisfied: requests in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: ftfy in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (6.2.0)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ftfy) (0.2.13)\n","Requirement already satisfied: ax-platform in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (0.4.0)\n","Requirement already satisfied: botorch==0.11.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (0.11.0)\n","Requirement already satisfied: jinja2 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (3.1.3)\n","Requirement already satisfied: pandas in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (2.2.1)\n","Requirement already satisfied: scipy in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (1.12.0)\n","Requirement already satisfied: scikit-learn in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (1.4.1.post1)\n","Requirement already satisfied: ipywidgets in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (8.1.2)\n","Requirement already satisfied: plotly>=5.12.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (5.22.0)\n","Requirement already satisfied: typeguard in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (2.13.3)\n","Requirement already satisfied: pyre-extensions in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ax-platform) (0.0.30)\n","Requirement already satisfied: multipledispatch in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from botorch==0.11.0->ax-platform) (1.0.0)\n","Requirement already satisfied: mpmath<=1.3,>=0.19 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from botorch==0.11.0->ax-platform) (1.3.0)\n","Requirement already satisfied: torch>=1.13.1 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from botorch==0.11.0->ax-platform) (2.3.0)\n","Requirement already satisfied: pyro-ppl>=1.8.4 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from botorch==0.11.0->ax-platform) (1.9.0)\n","Requirement already satisfied: gpytorch==1.11 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from botorch==0.11.0->ax-platform) (1.11)\n","Requirement already satisfied: linear-operator==0.5.1 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from botorch==0.11.0->ax-platform) (0.5.1)\n","Requirement already satisfied: jaxtyping>=0.2.9 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from linear-operator==0.5.1->botorch==0.11.0->ax-platform) (0.2.28)\n","Requirement already satisfied: tenacity>=6.2.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from plotly>=5.12.0->ax-platform) (8.2.3)\n","Requirement already satisfied: packaging in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from plotly>=5.12.0->ax-platform) (23.2)\n","Requirement already satisfied: comm>=0.1.3 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipywidgets->ax-platform) (0.2.1)\n","Requirement already satisfied: ipython>=6.1.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipywidgets->ax-platform) (8.22.1)\n","Requirement already satisfied: traitlets>=4.3.1 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipywidgets->ax-platform) (5.14.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.10 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipywidgets->ax-platform) (4.0.10)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipywidgets->ax-platform) (3.0.10)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from jinja2->ax-platform) (2.1.5)\n","Requirement already satisfied: numpy<2,>=1.23.2 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pandas->ax-platform) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pandas->ax-platform) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pandas->ax-platform) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pandas->ax-platform) (2024.1)\n","Requirement already satisfied: typing-inspect in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pyre-extensions->ax-platform) (0.9.0)\n","Requirement already satisfied: typing-extensions in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pyre-extensions->ax-platform) (4.11.0)\n","Requirement already satisfied: joblib>=1.2.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from scikit-learn->ax-platform) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from scikit-learn->ax-platform) (3.3.0)\n","Requirement already satisfied: decorator in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.1.6)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (3.0.43)\n","Requirement already satisfied: pygments>=2.4.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (2.17.2)\n","Requirement already satisfied: stack-data in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (0.6.3)\n","Requirement already satisfied: pexpect>4.3 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ax-platform) (4.9.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.11.0->ax-platform) (3.3.0)\n","Requirement already satisfied: pyro-api>=0.1.1 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.11.0->ax-platform) (0.1.2)\n","Requirement already satisfied: tqdm>=4.36 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pyro-ppl>=1.8.4->botorch==0.11.0->ax-platform) (4.66.4)\n","Requirement already satisfied: six>=1.5 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->ax-platform) (1.16.0)\n","Requirement already satisfied: filelock in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (3.14.0)\n","Requirement already satisfied: sympy in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (1.12)\n","Requirement already satisfied: networkx in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (3.3)\n","Requirement already satisfied: fsspec in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (2024.3.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from typing-inspect->pyre-extensions->ax-platform) (1.0.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->ax-platform) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->ax-platform) (0.7.0)\n","Requirement already satisfied: wcwidth in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->ax-platform) (0.2.13)\n","Requirement already satisfied: executing>=1.2.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (2.4.1)\n","Requirement already satisfied: pure-eval in /Users/senyuuri/workspace/tmp/pyenv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ax-platform) (0.2.2)\n"]}],"source":["# Data Preprocessing\n","# !pip install --upgrade pip\n","# !pip install transformers\n","# !pip install ftfy\n","# !pip install ax-platform"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1713253355969,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"N6galhMk3c_A"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/senyuuri/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /Users/senyuuri/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from gensim import utils\n","import gensim.models\n","from ftfy import fix_text\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1713253355970,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"XOgbVzXm0qiH"},"outputs":[],"source":["def data_preprocessing(df):\n","    # Remove rows with any missing values\n","    df = df.dropna()\n","    # Drop duplicates where both 'text' and 'label' are the same\n","    df = df.drop_duplicates(subset=['text', 'label'])\n","    # Drop all entries where 'text' appears more than once (across different labels)\n","    df = df.drop_duplicates(subset='text', keep=False)\n","    return df"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1713253355970,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"7qWCpNcp1tvt"},"outputs":[],"source":["train_data = data_preprocessing(train_data_processed)\n","test_data = data_preprocessing(test_data_processed)\n","test_dep_data = data_preprocessing(test_data_dep_processed)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1713253355970,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"D9C_DhxNySr_"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>35</th>\n","      <td>wake mohamed bouazizis desperate act selfimmol...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>utilitarianism emphasis maximizing overall uti...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>rich countries long grappled question meaningf...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>literature change anything question whether ti...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>nurturing stability prosperity strengthening u...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 text  label\n","35  wake mohamed bouazizis desperate act selfimmol...      1\n","36  utilitarianism emphasis maximizing overall uti...      1\n","37  rich countries long grappled question meaningf...      1\n","38  literature change anything question whether ti...      1\n","39  nurturing stability prosperity strengthening u...      1"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# combine the text into corpus\n","df_list = [train_data, test_data]\n","text_corpus = pd.concat(df_list)\n","text_corpus.tail()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3061,"status":"aborted","timestamp":1713253355970,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"cInjYGlR2rww"},"outputs":[],"source":["# define meta feature function\n","class TextFeatureExtractor:\n","    def __init__(self):\n","        self.stopwords = set(stopwords.words('english'))\n","\n","    def transform(self, df):\n","        # Store original columns to keep after transformation\n","        original_columns = df.columns.tolist()\n","        # Compute various text-related features\n","        df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n","        df['unique_word_count'] = df['text'].apply(lambda x: len(set(str(x).split())))\n","        df['%unique_word_total']= df['unique_word_count']/df['word_count']\n","        df['stop_word_count'] = df['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in self.stopwords]))\n","        df['%stop_word_total']=df['stop_word_count']/df['word_count']\n","        df['mean_word_length'] = df['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n","        df['char_count'] = df['text'].apply(lambda x: len(str(x)))\n","        df['mean_char_count_per_word']=df['char_count']/df['word_count']\n","        columns_to_keep = original_columns + ['%unique_word_total', '%stop_word_total','mean_word_length', 'mean_char_count_per_word']\n","        df = df[columns_to_keep]\n","        return df"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":3061,"status":"aborted","timestamp":1713253355970,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"c8O829Zj3Npo"},"outputs":[],"source":["meta_feature_list = ['word_count', 'unique_word_count', 'stop_word_count', 'url_count', 'mean_word_length', 'char_count']\n","text_feature_extractor = TextFeatureExtractor()\n","\n","train_data = text_feature_extractor.transform(train_data)\n","test_data = text_feature_extractor.transform(test_data)\n","test_dep_data = text_feature_extractor.transform(test_dep_data)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3060,"status":"aborted","timestamp":1713253355970,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"BMIaEL70zBiM"},"outputs":[],"source":["def normalise_text(text):\n","    text = fix_text(text)\n","    text = text.lower()  # lowercase\n","    text = text.translate(str.maketrans('', '', string.punctuation))    # remove punctuation\n","    text = re.sub(r'\\s{2,}', ' ', text)   # replace more than or equal to two white spaces into one white space.\n","    return text"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":3060,"status":"aborted","timestamp":1713253355970,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"90AnjLIJ3s3U"},"outputs":[],"source":["# fix text\n","text_corpus['text'] = text_corpus['text'].apply(lambda text: fix_text(text))\n","# normalise text\n","text_corpus['text'] = text_corpus['text'].apply(lambda text: normalise_text(text))"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":3060,"status":"aborted","timestamp":1713253355970,"user":{"displayName":"Janice","userId":"16402043149144267821"},"user_tz":-480},"id":"4e5OnINd7eF1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>carfree cities become subject increasing inter...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>car free cities carfree cities concept gaining...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sustainable urban future carfree cities emergi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>pioneering sustainable urban living era marked...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>path sustainable urban living age rapid urbani...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  carfree cities become subject increasing inter...      1\n","1  car free cities carfree cities concept gaining...      1\n","2  sustainable urban future carfree cities emergi...      1\n","3  pioneering sustainable urban living era marked...      1\n","4  path sustainable urban living age rapid urbani...      1"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["text_corpus.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Word2Vec + Logistic Regression"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>%unique_word_total</th>\n","      <th>%stop_word_total</th>\n","      <th>mean_word_length</th>\n","      <th>mean_char_count_per_word</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>carfree cities become subject increasing inter...</td>\n","      <td>1</td>\n","      <td>0.609499</td>\n","      <td>0.0</td>\n","      <td>7.627968</td>\n","      <td>8.625330</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>car free cities carfree cities concept gaining...</td>\n","      <td>1</td>\n","      <td>0.652542</td>\n","      <td>0.0</td>\n","      <td>7.632768</td>\n","      <td>8.629944</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sustainable urban future carfree cities emergi...</td>\n","      <td>1</td>\n","      <td>0.605042</td>\n","      <td>0.0</td>\n","      <td>7.775910</td>\n","      <td>8.773109</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>pioneering sustainable urban living era marked...</td>\n","      <td>1</td>\n","      <td>0.647399</td>\n","      <td>0.0</td>\n","      <td>7.679191</td>\n","      <td>8.676301</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>path sustainable urban living age rapid urbani...</td>\n","      <td>1</td>\n","      <td>0.622857</td>\n","      <td>0.0</td>\n","      <td>7.645714</td>\n","      <td>8.642857</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label  \\\n","0  carfree cities become subject increasing inter...      1   \n","1  car free cities carfree cities concept gaining...      1   \n","2  sustainable urban future carfree cities emergi...      1   \n","3  pioneering sustainable urban living era marked...      1   \n","4  path sustainable urban living age rapid urbani...      1   \n","\n","   %unique_word_total  %stop_word_total  mean_word_length  \\\n","0            0.609499               0.0          7.627968   \n","1            0.652542               0.0          7.632768   \n","2            0.605042               0.0          7.775910   \n","3            0.647399               0.0          7.679191   \n","4            0.622857               0.0          7.645714   \n","\n","   mean_char_count_per_word  \n","0                  8.625330  \n","1                  8.629944  \n","2                  8.773109  \n","3                  8.676301  \n","4                  8.642857  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["from gensim.models import Word2Vec\n","from sklearn.model_selection import train_test_split\n","\n","# Splitting data back into training and test datasets\n","test_data = test_data  # already defined in the previous code\n","train_data.shape, test_data.shape\n","train_data.head()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# Tokenize the text in each dataset\n","train_data['tokenized'] = train_data['text'].apply(word_tokenize)\n","test_data['tokenized'] = test_data['text'].apply(word_tokenize)\n","test_dep_data['tokenized'] = test_dep_data['text'].apply(word_tokenize)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# Train a Word2Vec model\n","model_w2v = Word2Vec(sentences=train_data['tokenized'], vector_size=100, window=5, min_count=1, workers=6)\n","\n","# Convert text to a mean vector\n","def document_vector(word2vec_model, doc):\n","    # remove out-of-vocabulary words\n","    doc = [word for word in doc if word in word2vec_model.wv.index_to_key]\n","    if len(doc) == 0:\n","        return np.zeros(word2vec_model.vector_size)\n","    return np.mean(word2vec_model.wv[doc], axis=0)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>%unique_word_total</th>\n","      <th>%stop_word_total</th>\n","      <th>mean_word_length</th>\n","      <th>mean_char_count_per_word</th>\n","      <th>tokenized</th>\n","      <th>doc_vector</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>carfree cities become subject increasing inter...</td>\n","      <td>1</td>\n","      <td>0.609499</td>\n","      <td>0.0</td>\n","      <td>7.627968</td>\n","      <td>8.625330</td>\n","      <td>[carfree, cities, become, subject, increasing,...</td>\n","      <td>[-0.014706382, -0.5769689, -0.8302832, 0.54603...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>car free cities carfree cities concept gaining...</td>\n","      <td>1</td>\n","      <td>0.652542</td>\n","      <td>0.0</td>\n","      <td>7.632768</td>\n","      <td>8.629944</td>\n","      <td>[car, free, cities, carfree, cities, concept, ...</td>\n","      <td>[-0.054762553, -0.52706367, -0.80999386, 0.430...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sustainable urban future carfree cities emergi...</td>\n","      <td>1</td>\n","      <td>0.605042</td>\n","      <td>0.0</td>\n","      <td>7.775910</td>\n","      <td>8.773109</td>\n","      <td>[sustainable, urban, future, carfree, cities, ...</td>\n","      <td>[0.04172768, -0.54994303, -0.74033755, 0.37289...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>pioneering sustainable urban living era marked...</td>\n","      <td>1</td>\n","      <td>0.647399</td>\n","      <td>0.0</td>\n","      <td>7.679191</td>\n","      <td>8.676301</td>\n","      <td>[pioneering, sustainable, urban, living, era, ...</td>\n","      <td>[-0.014413038, -0.53128386, -0.66398543, 0.356...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>path sustainable urban living age rapid urbani...</td>\n","      <td>1</td>\n","      <td>0.622857</td>\n","      <td>0.0</td>\n","      <td>7.645714</td>\n","      <td>8.642857</td>\n","      <td>[path, sustainable, urban, living, age, rapid,...</td>\n","      <td>[-0.01715994, -0.5561988, -0.68364155, 0.43044...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label  \\\n","0  carfree cities become subject increasing inter...      1   \n","1  car free cities carfree cities concept gaining...      1   \n","2  sustainable urban future carfree cities emergi...      1   \n","3  pioneering sustainable urban living era marked...      1   \n","4  path sustainable urban living age rapid urbani...      1   \n","\n","   %unique_word_total  %stop_word_total  mean_word_length  \\\n","0            0.609499               0.0          7.627968   \n","1            0.652542               0.0          7.632768   \n","2            0.605042               0.0          7.775910   \n","3            0.647399               0.0          7.679191   \n","4            0.622857               0.0          7.645714   \n","\n","   mean_char_count_per_word  \\\n","0                  8.625330   \n","1                  8.629944   \n","2                  8.773109   \n","3                  8.676301   \n","4                  8.642857   \n","\n","                                           tokenized  \\\n","0  [carfree, cities, become, subject, increasing,...   \n","1  [car, free, cities, carfree, cities, concept, ...   \n","2  [sustainable, urban, future, carfree, cities, ...   \n","3  [pioneering, sustainable, urban, living, era, ...   \n","4  [path, sustainable, urban, living, age, rapid,...   \n","\n","                                          doc_vector  \n","0  [-0.014706382, -0.5769689, -0.8302832, 0.54603...  \n","1  [-0.054762553, -0.52706367, -0.80999386, 0.430...  \n","2  [0.04172768, -0.54994303, -0.74033755, 0.37289...  \n","3  [-0.014413038, -0.53128386, -0.66398543, 0.356...  \n","4  [-0.01715994, -0.5561988, -0.68364155, 0.43044...  "]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["train_data['doc_vector'] = train_data['tokenized'].apply(lambda x: document_vector(model_w2v, x))\n","test_data['doc_vector'] = test_data['tokenized'].apply(lambda x: document_vector(model_w2v, x))\n","test_dep_data['doc_vector'] = test_dep_data['tokenized'].apply(lambda x: document_vector(model_w2v, x))\n","train_data.head()\n","\n","# save the train and test data as pickle file\n","# train_data.to_pickle('train_data.pkl')\n","# test_data.to_pickle('test_data.pkl')"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from sklearn.metrics import roc_auc_score, mean_squared_error\n","\n","# load pickles to save time from running all above code\n","# train_data = pd.read_pickle('train_data.pkl')\n","# test_data = pd.read_pickle('test_data.pkl')\n","\n","# Extract feature vectors for training and testing\n","X_train = np.array(list(train_data['doc_vector']))\n","X_test = np.array(list(test_data['doc_vector']))\n","X_test_dep = np.array(list(test_dep_data['doc_vector']))\n","y_train = train_data['label'].values\n","y_test = test_data['label'].values\n","y_test_dep = test_dep_data['label'].values"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression - Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.20      0.31        20\n","           1       0.53      0.90      0.67        20\n","\n","    accuracy                           0.55        40\n","   macro avg       0.60      0.55      0.49        40\n","weighted avg       0.60      0.55      0.49        40\n","\n","Logistic Regression - Confusion Matrix:\n","[[ 4 16]\n"," [ 2 18]]\n","AUC: 0.55\n","\n","=========== test_dep =================\n","\n","Logistic Regression - Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.84      0.86        25\n","           1       0.85      0.88      0.86        25\n","\n","    accuracy                           0.86        50\n","   macro avg       0.86      0.86      0.86        50\n","weighted avg       0.86      0.86      0.86        50\n","\n","Logistic Regression - Confusion Matrix:\n","[[21  4]\n"," [ 3 22]]\n","AUC: 0.86\n"]}],"source":["# Train a logistic regression model\n","log_reg = LogisticRegression(max_iter=50000) # set max_iter=50000 as the model does not converge with default value\n","log_reg.fit(X_train, y_train)\n","\n","# Predictions and evaluations\n","y_pred = log_reg.predict(X_test)\n","print(\"Logistic Regression - Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","print(\"Logistic Regression - Confusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n","print('AUC:', roc_auc_score(y_test, y_pred))\n","\n","print(\"\\n=========== test_dep =================\\n\")\n","\n","y_pred_dep = log_reg.predict(X_test_dep)\n","print(\"Logistic Regression - Classification Report:\")\n","print(classification_report(y_test_dep, y_pred_dep))\n","print(\"Logistic Regression - Confusion Matrix:\")\n","print(confusion_matrix(y_test_dep, y_pred_dep))\n","print('AUC:', roc_auc_score(y_test_dep, y_pred_dep))\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 11183, number of negative: 16035\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005524 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 25500\n","[LightGBM] [Info] Number of data points in the train set: 27218, number of used features: 100\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.410868 -> initscore=-0.360379\n","[LightGBM] [Info] Start training from score -0.360379\n","LightGBM - Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.05      0.10        20\n","           1       0.51      1.00      0.68        20\n","\n","    accuracy                           0.53        40\n","   macro avg       0.76      0.53      0.39        40\n","weighted avg       0.76      0.53      0.39        40\n","\n","LightGBM - Confusion Matrix:\n","[[ 1 19]\n"," [ 0 20]]\n","AUC: 0.525\n","\n","=========== test_dep =================\n","\n","LightGBM - Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.20      0.33        25\n","           1       0.56      1.00      0.71        25\n","\n","    accuracy                           0.60        50\n","   macro avg       0.78      0.60      0.52        50\n","weighted avg       0.78      0.60      0.52        50\n","\n","LightGBM - Confusion Matrix:\n","[[ 5 20]\n"," [ 0 25]]\n","AUC: 0.6\n"]}],"source":["# Train a LightGBM model\n","# choose LightGBM over SVC & RandomForest as it is more scalable and faster to train\n","import lightgbm as lgb\n","lgbm = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.05, max_depth=-1)\n","lgbm.fit(X_train, y_train)\n","\n","# Predictions and evaluations\n","y_pred = lgbm.predict(X_test)\n","print(\"LightGBM - Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","print(\"LightGBM - Confusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n","print('AUC:', roc_auc_score(y_test, y_pred))\n","\n","print(\"\\n=========== test_dep =================\\n\")\n","\n","y_pred_dep = lgbm.predict(X_test_dep)\n","print(\"LightGBM - Classification Report:\")\n","print(classification_report(y_test_dep, y_pred_dep))\n","print(\"LightGBM - Confusion Matrix:\")\n","print(confusion_matrix(y_test_dep, y_pred_dep))\n","print('AUC:', roc_auc_score(y_test_dep, y_pred_dep))\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0:\tlearn: 0.6250764\ttotal: 26.4ms\tremaining: 2.61s\n","1:\tlearn: 0.5694539\ttotal: 35.1ms\tremaining: 1.72s\n","2:\tlearn: 0.5200941\ttotal: 42.2ms\tremaining: 1.36s\n","3:\tlearn: 0.4807498\ttotal: 50.2ms\tremaining: 1.21s\n","4:\tlearn: 0.4444753\ttotal: 56.2ms\tremaining: 1.07s\n","5:\tlearn: 0.4096700\ttotal: 62.3ms\tremaining: 976ms\n","6:\tlearn: 0.3833262\ttotal: 67.7ms\tremaining: 900ms\n","7:\tlearn: 0.3596298\ttotal: 73.5ms\tremaining: 846ms\n","8:\tlearn: 0.3405934\ttotal: 80.1ms\tremaining: 810ms\n","9:\tlearn: 0.3198184\ttotal: 85.5ms\tremaining: 770ms\n","10:\tlearn: 0.3051654\ttotal: 91.4ms\tremaining: 740ms\n","11:\tlearn: 0.2883879\ttotal: 96.7ms\tremaining: 709ms\n","12:\tlearn: 0.2778217\ttotal: 102ms\tremaining: 682ms\n","13:\tlearn: 0.2645782\ttotal: 107ms\tremaining: 659ms\n","14:\tlearn: 0.2530048\ttotal: 113ms\tremaining: 640ms\n","15:\tlearn: 0.2432794\ttotal: 118ms\tremaining: 619ms\n","16:\tlearn: 0.2355100\ttotal: 123ms\tremaining: 601ms\n","17:\tlearn: 0.2268649\ttotal: 129ms\tremaining: 588ms\n","18:\tlearn: 0.2175869\ttotal: 134ms\tremaining: 573ms\n","19:\tlearn: 0.2104616\ttotal: 140ms\tremaining: 559ms\n","20:\tlearn: 0.2038642\ttotal: 145ms\tremaining: 546ms\n","21:\tlearn: 0.1978947\ttotal: 151ms\tremaining: 534ms\n","22:\tlearn: 0.1919928\ttotal: 156ms\tremaining: 523ms\n","23:\tlearn: 0.1869821\ttotal: 162ms\tremaining: 514ms\n","24:\tlearn: 0.1833997\ttotal: 167ms\tremaining: 502ms\n","25:\tlearn: 0.1791242\ttotal: 173ms\tremaining: 491ms\n","26:\tlearn: 0.1746853\ttotal: 179ms\tremaining: 483ms\n","27:\tlearn: 0.1707636\ttotal: 184ms\tremaining: 473ms\n","28:\tlearn: 0.1672581\ttotal: 189ms\tremaining: 462ms\n","29:\tlearn: 0.1635764\ttotal: 195ms\tremaining: 455ms\n","30:\tlearn: 0.1608670\ttotal: 200ms\tremaining: 446ms\n","31:\tlearn: 0.1583496\ttotal: 205ms\tremaining: 436ms\n","32:\tlearn: 0.1555824\ttotal: 212ms\tremaining: 430ms\n","33:\tlearn: 0.1527490\ttotal: 217ms\tremaining: 421ms\n","34:\tlearn: 0.1504211\ttotal: 222ms\tremaining: 413ms\n","35:\tlearn: 0.1475804\ttotal: 229ms\tremaining: 407ms\n","36:\tlearn: 0.1454228\ttotal: 234ms\tremaining: 398ms\n","37:\tlearn: 0.1427829\ttotal: 239ms\tremaining: 390ms\n","38:\tlearn: 0.1408796\ttotal: 246ms\tremaining: 385ms\n","39:\tlearn: 0.1387891\ttotal: 252ms\tremaining: 378ms\n","40:\tlearn: 0.1371678\ttotal: 257ms\tremaining: 370ms\n","41:\tlearn: 0.1347723\ttotal: 263ms\tremaining: 364ms\n","42:\tlearn: 0.1331374\ttotal: 269ms\tremaining: 357ms\n","43:\tlearn: 0.1314563\ttotal: 275ms\tremaining: 350ms\n","44:\tlearn: 0.1301294\ttotal: 280ms\tremaining: 342ms\n","45:\tlearn: 0.1286501\ttotal: 285ms\tremaining: 335ms\n","46:\tlearn: 0.1271819\ttotal: 292ms\tremaining: 329ms\n","47:\tlearn: 0.1256866\ttotal: 297ms\tremaining: 321ms\n","48:\tlearn: 0.1242602\ttotal: 302ms\tremaining: 315ms\n","49:\tlearn: 0.1229033\ttotal: 307ms\tremaining: 307ms\n","50:\tlearn: 0.1218272\ttotal: 313ms\tremaining: 301ms\n","51:\tlearn: 0.1206824\ttotal: 318ms\tremaining: 294ms\n","52:\tlearn: 0.1195189\ttotal: 323ms\tremaining: 286ms\n","53:\tlearn: 0.1186159\ttotal: 329ms\tremaining: 280ms\n","54:\tlearn: 0.1173858\ttotal: 334ms\tremaining: 273ms\n","55:\tlearn: 0.1163758\ttotal: 342ms\tremaining: 269ms\n","56:\tlearn: 0.1154703\ttotal: 347ms\tremaining: 262ms\n","57:\tlearn: 0.1143098\ttotal: 353ms\tremaining: 256ms\n","58:\tlearn: 0.1133638\ttotal: 359ms\tremaining: 250ms\n","59:\tlearn: 0.1124584\ttotal: 364ms\tremaining: 243ms\n","60:\tlearn: 0.1116639\ttotal: 369ms\tremaining: 236ms\n","61:\tlearn: 0.1109224\ttotal: 375ms\tremaining: 230ms\n","62:\tlearn: 0.1098578\ttotal: 379ms\tremaining: 223ms\n","63:\tlearn: 0.1088670\ttotal: 385ms\tremaining: 216ms\n","64:\tlearn: 0.1080503\ttotal: 390ms\tremaining: 210ms\n","65:\tlearn: 0.1073857\ttotal: 395ms\tremaining: 203ms\n","66:\tlearn: 0.1064943\ttotal: 400ms\tremaining: 197ms\n","67:\tlearn: 0.1056585\ttotal: 405ms\tremaining: 191ms\n","68:\tlearn: 0.1049824\ttotal: 410ms\tremaining: 184ms\n","69:\tlearn: 0.1043421\ttotal: 415ms\tremaining: 178ms\n","70:\tlearn: 0.1036987\ttotal: 420ms\tremaining: 172ms\n","71:\tlearn: 0.1030093\ttotal: 425ms\tremaining: 165ms\n","72:\tlearn: 0.1023425\ttotal: 430ms\tremaining: 159ms\n","73:\tlearn: 0.1019483\ttotal: 435ms\tremaining: 153ms\n","74:\tlearn: 0.1012928\ttotal: 441ms\tremaining: 147ms\n","75:\tlearn: 0.1005951\ttotal: 446ms\tremaining: 141ms\n","76:\tlearn: 0.1000236\ttotal: 451ms\tremaining: 135ms\n","77:\tlearn: 0.0995275\ttotal: 458ms\tremaining: 129ms\n","78:\tlearn: 0.0990513\ttotal: 462ms\tremaining: 123ms\n","79:\tlearn: 0.0984339\ttotal: 468ms\tremaining: 117ms\n","80:\tlearn: 0.0978470\ttotal: 473ms\tremaining: 111ms\n","81:\tlearn: 0.0973384\ttotal: 478ms\tremaining: 105ms\n","82:\tlearn: 0.0968296\ttotal: 484ms\tremaining: 99.1ms\n","83:\tlearn: 0.0961692\ttotal: 489ms\tremaining: 93.2ms\n","84:\tlearn: 0.0958486\ttotal: 494ms\tremaining: 87.3ms\n","85:\tlearn: 0.0951785\ttotal: 500ms\tremaining: 81.4ms\n","86:\tlearn: 0.0946438\ttotal: 506ms\tremaining: 75.6ms\n","87:\tlearn: 0.0942105\ttotal: 512ms\tremaining: 69.8ms\n","88:\tlearn: 0.0936574\ttotal: 517ms\tremaining: 63.9ms\n","89:\tlearn: 0.0929213\ttotal: 522ms\tremaining: 58ms\n","90:\tlearn: 0.0923049\ttotal: 527ms\tremaining: 52.1ms\n","91:\tlearn: 0.0918595\ttotal: 532ms\tremaining: 46.3ms\n","92:\tlearn: 0.0914290\ttotal: 537ms\tremaining: 40.4ms\n","93:\tlearn: 0.0908469\ttotal: 543ms\tremaining: 34.6ms\n","94:\tlearn: 0.0904958\ttotal: 548ms\tremaining: 28.8ms\n","95:\tlearn: 0.0901208\ttotal: 554ms\tremaining: 23.1ms\n","96:\tlearn: 0.0896116\ttotal: 559ms\tremaining: 17.3ms\n","97:\tlearn: 0.0891611\ttotal: 564ms\tremaining: 11.5ms\n","98:\tlearn: 0.0887093\ttotal: 570ms\tremaining: 5.76ms\n","99:\tlearn: 0.0882997\ttotal: 575ms\tremaining: 0us\n","CatBoost - Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.05      0.10        20\n","           1       0.51      1.00      0.68        20\n","\n","    accuracy                           0.53        40\n","   macro avg       0.76      0.53      0.39        40\n","weighted avg       0.76      0.53      0.39        40\n","\n","CatBoost - Confusion Matrix:\n","[[ 1 19]\n"," [ 0 20]]\n","AUC: 0.525\n","\n","=========== test_dep =================\n","\n","CatBoost - Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.20      0.33        25\n","           1       0.56      1.00      0.71        25\n","\n","    accuracy                           0.60        50\n","   macro avg       0.78      0.60      0.52        50\n","weighted avg       0.78      0.60      0.52        50\n","\n","CatBoost - Confusion Matrix:\n","[[ 5 20]\n"," [ 0 25]]\n","AUC: 0.6\n"]}],"source":["# Train a CatBoost model\n","from catboost import CatBoostClassifier\n","catboost = CatBoostClassifier(iterations=100, learning_rate=0.05, depth=5)\n","catboost.fit(X_train, y_train)\n","\n","# Predictions and evaluations\n","y_pred = catboost.predict(X_test)\n","print(\"CatBoost - Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","print(\"CatBoost - Confusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n","print('AUC:', roc_auc_score(y_test, y_pred))\n","\n","print(\"\\n=========== test_dep =================\\n\")\n","\n","y_pred_dep = catboost.predict(X_test_dep)\n","print(\"CatBoost - Classification Report:\")\n","print(classification_report(y_test_dep, y_pred_dep))\n","print(\"CatBoost - Confusion Matrix:\")\n","print(confusion_matrix(y_test_dep, y_pred_dep))\n","print('AUC:', roc_auc_score(y_test_dep, y_pred_dep))\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
